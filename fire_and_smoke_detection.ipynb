{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/azarenkova-git/Fire-and-smoke-detection/blob/main/fire_and_smoke_detection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2i8MRYluZpX6",
        "outputId": "680e2186-8a4e-45d6-e873-ad8a64a1d520",
        "collapsed": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /gdrive; to attempt to forcibly remount, call drive.mount(\"/gdrive\", force_remount=True).\n",
            "/gdrive/MyDrive/работа/fire_and_smoke_detection\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/gdrive')\n",
        "%cd \"/gdrive/MyDrive/работа/fire_and_smoke_detection\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import random\n",
        "import shutil\n",
        "import yaml\n",
        "from ultralytics import YOLO"
      ],
      "metadata": {
        "id": "QNksdoJE6uBc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Функция для преобразования bbox из COCO-формата в YOLO-формат\n",
        "\n"
      ],
      "metadata": {
        "id": "1JUEFkSr57lS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def convert_bbox(image_size, bbox):\n",
        "    width, height = image_size\n",
        "    x, y, w, h = bbox\n",
        "\n",
        "    x_center = x + w / 2.0\n",
        "    y_center = y + h / 2.0\n",
        "\n",
        "    x_center_norm = x_center / width\n",
        "    y_center_norm = y_center / height\n",
        "    w_norm = w / width\n",
        "    h_norm = h / height\n",
        "\n",
        "    return x_center_norm, y_center_norm, w_norm, h_norm\n",
        "\n",
        "\n",
        "def process_annotations(json_path, output_dir, valid_categories):\n",
        "    with open(json_path, 'r', encoding='utf-8') as f:\n",
        "        data = json.load(f)\n",
        "    images_info = {img['id']: img for img in data['images']}\n",
        "\n",
        "    annotations_per_image = {}\n",
        "    for ann in data['annotations']:\n",
        "        cat_id = ann['category_id']\n",
        "        if cat_id in valid_categories:\n",
        "            image_id = ann['image_id']\n",
        "            if image_id not in annotations_per_image:\n",
        "                annotations_per_image[image_id] = []\n",
        "            annotations_per_image[image_id].append(ann)\n",
        "\n",
        "    os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "    for image_id, img_info in images_info.items():\n",
        "        file_name = img_info['file_name']\n",
        "        img_width = img_info['width']\n",
        "        img_height = img_info['height']\n",
        "\n",
        "        base_name = os.path.splitext(os.path.basename(file_name))[0]\n",
        "        txt_path = os.path.join(output_dir, base_name + '.txt')\n",
        "\n",
        "        ann_list = annotations_per_image.get(image_id, [])\n",
        "\n",
        "        with open(txt_path, 'w') as out_file:\n",
        "            for ann in ann_list:\n",
        "                bbox = ann['bbox']\n",
        "                x_c, y_c, w_n, h_n = convert_bbox((img_width, img_height), bbox)\n",
        "\n",
        "                new_cat_id = valid_categories[ann['category_id']]\n",
        "                line = f\"{new_cat_id} {x_c:.6f} {y_c:.6f} {w_n:.6f} {h_n:.6f}\\n\"\n",
        "                out_file.write(line)\n",
        "\n",
        "train_json_path = os.path.join(\"data\", \"475_fire_train\", \"annotations\", \"instances_default.json\")\n",
        "train_output_dir = os.path.join(\"data\", \"475_fire_train\", \"labels\")\n",
        "\n",
        "val_json_path = os.path.join(\"data\", \"474_fire_val\", \"annotations\", \"instances_default.json\")\n",
        "val_output_dir = os.path.join(\"data\", \"474_fire_val\", \"labels\")\n",
        "\n",
        "\n",
        "process_annotations(train_json_path, train_output_dir, valid_categories)\n",
        "process_annotations(val_json_path, val_output_dir, valid_categories)"
      ],
      "metadata": {
        "id": "uDsznMn2aApE",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Перемещаю данные из train и val в предыдущие папки\n"
      ],
      "metadata": {
        "id": "fpKhyvuM6erv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_dir = os.path.join(\"data\", \"475_fire_train\", \"images\", \"train\")\n",
        "train_target = os.path.join(\"data\", \"475_fire_train\", \"images\")\n",
        "\n",
        "val_dir = os.path.join(\"data\", \"474_fire_val\", \"images\", \"val\")\n",
        "val_target = os.path.join(\"data\", \"474_fire_val\", \"images\")\n",
        "\n",
        "def move_images(src_dir, dst_dir):\n",
        "    if not os.path.exists(src_dir):\n",
        "\n",
        "        return\n",
        "    if not os.path.exists(dst_dir):\n",
        "        os.makedirs(dst_dir, exist_ok=True)\n",
        "\n",
        "\n",
        "    for filename in os.listdir(src_dir):\n",
        "        src_file = os.path.join(src_dir, filename)\n",
        "        dst_file = os.path.join(dst_dir, filename)\n",
        "        if os.path.isfile(src_file):\n",
        "            shutil.move(src_file, dst_file)\n",
        "\n",
        "    if not os.listdir(src_dir):\n",
        "        os.rmdir(src_dir)\n",
        "\n",
        "move_images(train_dir, train_target)\n",
        "move_images(val_dir, val_target)"
      ],
      "metadata": {
        "id": "hfLhcCRJbDIW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install ultralytics"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "E9rLv-mjbQq4",
        "outputId": "87ee9dfa-8bcf-4ed6-b7b2-c24c0f8f7057"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: ultralytics in /usr/local/lib/python3.11/dist-packages (8.3.107)\n",
            "Requirement already satisfied: numpy<=2.1.1,>=1.23.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.0.2)\n",
            "Requirement already satisfied: matplotlib>=3.3.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (3.10.0)\n",
            "Requirement already satisfied: opencv-python>=4.6.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (4.11.0.86)\n",
            "Requirement already satisfied: pillow>=7.1.2 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (11.1.0)\n",
            "Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (6.0.2)\n",
            "Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.32.3)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (1.14.1)\n",
            "Requirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.6.0+cu124)\n",
            "Requirement already satisfied: torchvision>=0.9.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (0.21.0+cu124)\n",
            "Requirement already satisfied: tqdm>=4.64.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (4.67.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from ultralytics) (5.9.5)\n",
            "Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.11/dist-packages (from ultralytics) (9.0.0)\n",
            "Requirement already satisfied: pandas>=1.1.4 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.2.2)\n",
            "Requirement already satisfied: seaborn>=0.11.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (0.13.2)\n",
            "Requirement already satisfied: ultralytics-thop>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.0.14)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (4.57.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (24.2)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.1.4->ultralytics) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.1.4->ultralytics) (2025.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (2025.1.31)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (4.13.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (2025.3.2)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.8.0->ultralytics) (1.3.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.17.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.8.0->ultralytics) (3.0.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Разделение данных train на две части - train и dev, в соотношении 80/20"
      ],
      "metadata": {
        "id": "kty5FUJ27gWC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def split_train_dev(source_images_dir, source_labels_dir, dest_train_images, dest_train_labels, dest_dev_images, dest_dev_labels, dev_ratio=0.2, seed=42):\n",
        "\n",
        "    os.makedirs(dest_train_images, exist_ok=True)\n",
        "    os.makedirs(dest_train_labels, exist_ok=True)\n",
        "    os.makedirs(dest_dev_images, exist_ok=True)\n",
        "    os.makedirs(dest_dev_labels, exist_ok=True)\n",
        "\n",
        "    image_files = [f for f in os.listdir(source_images_dir) if f.lower().endswith('.jpg')]\n",
        "    image_files.sort()\n",
        "    random.seed(seed)\n",
        "    random.shuffle(image_files)\n",
        "\n",
        "    num_images = len(image_files)\n",
        "    num_dev = int(num_images * dev_ratio)\n",
        "\n",
        "    dev_files = image_files[:num_dev]\n",
        "    train_files = image_files[num_dev:]\n",
        "\n",
        "    for file in train_files:\n",
        "        src_img_path = os.path.join(source_images_dir, file)\n",
        "        dest_img_path = os.path.join(dest_train_images, file)\n",
        "        shutil.copy(src_img_path, dest_img_path)\n",
        "\n",
        "        label_file = file.rsplit('.', 1)[0] + '.txt'\n",
        "        src_label_path = os.path.join(source_labels_dir, label_file)\n",
        "        if os.path.exists(src_label_path):\n",
        "            dest_label_path = os.path.join(dest_train_labels, label_file)\n",
        "            shutil.copy(src_label_path, dest_label_path)\n",
        "\n",
        "    for file in dev_files:\n",
        "        src_img_path = os.path.join(source_images_dir, file)\n",
        "        dest_img_path = os.path.join(dest_dev_images, file)\n",
        "        shutil.copy(src_img_path, dest_img_path)\n",
        "\n",
        "        label_file = file.rsplit('.', 1)[0] + '.txt'\n",
        "        src_label_path = os.path.join(source_labels_dir, label_file)\n",
        "        if os.path.exists(src_label_path):\n",
        "            dest_label_path = os.path.join(dest_dev_labels, label_file)\n",
        "            shutil.copy(src_label_path, dest_label_path)\n",
        "\n",
        "    print(f\"Деление завершено: {len(train_files)} изображений для train, {len(dev_files)} для dev.\")\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    base_dir = './data/475_fire_train'\n",
        "    source_images_dir = os.path.join(base_dir, 'images')\n",
        "    source_labels_dir = os.path.join(base_dir, 'labels')\n",
        "\n",
        "    dest_train_images = os.path.join(base_dir, 'train', 'images')\n",
        "    dest_train_labels = os.path.join(base_dir, 'train', 'labels')\n",
        "    dest_dev_images = os.path.join(base_dir, 'dev', 'images')\n",
        "    dest_dev_labels = os.path.join(base_dir, 'dev', 'labels')\n",
        "\n",
        "    split_train_dev(source_images_dir, source_labels_dir,\n",
        "                    dest_train_images, dest_train_labels,\n",
        "                    dest_dev_images, dest_dev_labels,\n",
        "                    dev_ratio=0.2, seed=42)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JvP-BQX4b852",
        "outputId": "26c1c005-4d5f-4b94-fae5-4783c332913d",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Деление завершено: 914 изображений для train, 228 для dev.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Первый yaml файл"
      ],
      "metadata": {
        "id": "-daiywDC79gp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import yaml\n",
        "from ultralytics import YOLO\n",
        "\n",
        "\n",
        "data_dict_new = {\n",
        "    \"train\": \"/gdrive/MyDrive/работа/fire_and_smoke_detection/data/475_fire_train/train/images\",\n",
        "    \"val\": \"/gdrive/MyDrive/работа/fire_and_smoke_detection/data/475_fire_train/dev/images\",\n",
        "    \"test\": \"/gdrive/MyDrive/работа/fire_and_smoke_detection/data/474_fire_val/images\",\n",
        "    \"nc\": 2,\n",
        "    \"names\": [\"smoke\", \"fire\"]\n",
        "}\n",
        "\n",
        "yaml_path_correct = \"data_correct.yaml\"\n",
        "with open(yaml_path_correct, \"w\") as f:\n",
        "    yaml.dump(data_dict_new, f)\n",
        "\n",
        "print(\"YAML конфигурация сохранена в\", yaml_path_correct)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wy_r63GKcXCS",
        "outputId": "470f987d-e95b-4e5d-d4ed-12ac44de68f1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "YAML конфигурация сохранена в data_correct.yaml\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Обучение моделей\n"
      ],
      "metadata": {
        "id": "NwdSzGnt77CW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = YOLO(\"yolov8s.pt\")\n",
        "\n",
        "\n",
        "train_results = model.train(\n",
        "    data=yaml_path_correct,\n",
        "    epochs=50,\n",
        "    imgsz=640,\n",
        "    batch=16\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "QvzvO8mx834i",
        "outputId": "5d918ec1-c3c9-484c-8e79-50ddb9025a7f",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'yaml_path' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-50-4af5c2aec710>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m train_results = model.train(\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0myaml_path\u001b[0m\u001b[0;34m,\u001b[0m     \u001b[0;31m# используем созданный yaml файл\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m     \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m          \u001b[0;31m# количество эпох; можно изменить по необходимости\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mimgsz\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m640\u001b[0m\u001b[0;34m,\u001b[0m          \u001b[0;31m# размер изображений\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'yaml_path' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_1 = YOLO(\"yolov8m.pt\")\n",
        "\n",
        "\n",
        "train_results_1 = model_1.train(\n",
        "    data=yaml_path_correct,\n",
        "    epochs=50,\n",
        "    imgsz=640,\n",
        "    batch=16\n",
        ")\n"
      ],
      "metadata": {
        "id": "x4wlB9Qgatri",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_2 = YOLO(\"yolov8l.pt\")\n",
        "\n",
        "\n",
        "train_results_1 = model_2.train(\n",
        "    data=yaml_path_correct,\n",
        "    epochs=50,\n",
        "    imgsz=640,\n",
        "    batch=16\n",
        ")"
      ],
      "metadata": {
        "id": "kHWHXeL-zIHw",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Модель с самыми лучшими показателями."
      ],
      "metadata": {
        "id": "klFTh-dqAKGw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = YOLO(\"yolov8m.pt\")\n",
        "\n",
        "train_results = model.train(\n",
        "    data=\"yaml_path_correct\",\n",
        "    epochs=100,\n",
        "    imgsz=640,\n",
        "    batch=32,\n",
        "    optimizer=\"sgd\",\n",
        "    lr0=0.01\n",
        ")"
      ],
      "metadata": {
        "id": "nVSDxe0n_t40"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Модель yolov5 не показала хороших результатов, я решила к ней не возвращаться.\n"
      ],
      "metadata": {
        "id": "uY7lX7c3_i3R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/ultralytics/yolov5.git\n",
        "!pip install -r yolov5/requirements.txt"
      ],
      "metadata": {
        "collapsed": true,
        "id": "KsY45zPfVqne"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python /gdrive/MyDrive/работа/fire_and_smoke_detection/yolov5/train.py --img 640 --batch 32 --epochs 100 --data data_correct.yaml --weights yolov5s.pt --optimizer SGD --hyp /gdrive/MyDrive/работа/fire_and_smoke_detection/custom_hyp.yaml --name fire_detect_exp"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "lGHno6BV-XjK",
        "outputId": "25def996-446c-46d4-e256-ecdf05f2addc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/gdrive/MyDrive/работа/fire_and_smoke_detection/yolov5/train.py\", line 33, in <module>\n",
            "    import numpy as np\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/numpy/__init__.py\", line 181, in <module>\n",
            "    from . import lib\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/numpy/lib/__init__.py\", line 16, in <module>\n",
            "    from . import npyio\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/numpy/lib/npyio.py\", line 1, in <module>\n",
            "    from ._npyio_impl import (\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/numpy/lib/_npyio_impl.py\", line 17, in <module>\n",
            "    from . import format\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/numpy/lib/format.py\", line 170, in <module>\n",
            "    from numpy.lib._utils_impl import drop_metadata\n",
            "  File \"<frozen importlib._bootstrap>\", line 1176, in _find_and_load\n",
            "  File \"<frozen importlib._bootstrap>\", line 1147, in _find_and_load_unlocked\n",
            "  File \"<frozen importlib._bootstrap>\", line 690, in _load_unlocked\n",
            "  File \"<frozen importlib._bootstrap_external>\", line 936, in exec_module\n",
            "  File \"<frozen importlib._bootstrap_external>\", line 1032, in get_code\n",
            "  File \"<frozen importlib._bootstrap_external>\", line 1131, in get_data\n",
            "KeyboardInterrupt\n",
            "^C\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Попытка аугментации (чтобы увеличить число изображений с дымом). Метрики оказались хуже, возможно, было бы уместно доработать и  это было дало метрики больше."
      ],
      "metadata": {
        "id": "LPf5teFBAaD_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "import albumentations as A\n",
        "\n",
        "train_images_dir = \"/gdrive/MyDrive/работа/fire_and_smoke_detection/data/475_fire_train/train/images\"\n",
        "train_labels_dir = \"/gdrive/MyDrive/работа/fire_and_smoke_detection/data/475_fire_train/train/labels\"\n",
        "augmented_images_dir = \"/gdrive/MyDrive/работа/fire_and_smoke_detection/data/475_fire_train/train_augmented/images\"\n",
        "augmented_labels_dir = \"/gdrive/MyDrive/работа/fire_and_smoke_detection/data/475_fire_train/train_augmented/labels\"\n",
        "\n",
        "\n",
        "\n",
        "def yolo_to_corners(bbox):\n",
        "\n",
        "    x_center, y_center, width, height = bbox\n",
        "    x_min = x_center - width / 2\n",
        "    y_min = y_center - height / 2\n",
        "    x_max = x_center + width / 2\n",
        "    y_max = y_center + height / 2\n",
        "    return x_min, y_min, x_max, y_max\n",
        "\n",
        "def corners_to_yolo(corners):\n",
        "\n",
        "    x_min, y_min, x_max, y_max = corners\n",
        "    x_center = (x_min + x_max) / 2\n",
        "    y_center = (y_min + y_max) / 2\n",
        "    width = x_max - x_min\n",
        "    height = y_max - y_min\n",
        "    return [x_center, y_center, width, height]\n",
        "\n",
        "def adjust_yolo_bbox(bbox):\n",
        "\n",
        "    x_min, y_min, x_max, y_max = yolo_to_corners(bbox)\n",
        "    # Обрезаем каждое значение в диапазон [0, 1]\n",
        "    x_min = max(0.0, x_min)\n",
        "    y_min = max(0.0, y_min)\n",
        "    x_max = min(1.0, x_max)\n",
        "    y_max = min(1.0, y_max)\n",
        "    return corners_to_yolo((x_min, y_min, x_max, y_max))\n",
        "\n",
        "def load_labels(label_path):\n",
        "\n",
        "    bboxes = []\n",
        "    labels = []\n",
        "    if not os.path.exists(label_path):\n",
        "        return bboxes, labels\n",
        "    with open(label_path, 'r') as f:\n",
        "        for line in f.readlines():\n",
        "            parts = line.strip().split()\n",
        "            if len(parts) != 5:\n",
        "                continue\n",
        "            cls = int(parts[0])\n",
        "            raw_bbox = list(map(float, parts[1:]))\n",
        "            # Даже если исходно все значения корректны, из-за округления\n",
        "            # после преобразования могут получаться незначительные отрицательные значения.\n",
        "            bbox = adjust_yolo_bbox(raw_bbox)\n",
        "            bboxes.append(bbox)\n",
        "            labels.append(cls)\n",
        "    return bboxes, labels\n",
        "\n",
        "def save_labels(label_path, bboxes, labels):\n",
        "\n",
        "    with open(label_path, 'w') as f:\n",
        "        for cls, bbox in zip(labels, bboxes):\n",
        "            bbox_str = \" \".join(map(str, bbox))\n",
        "            f.write(f\"{cls} {bbox_str}\\n\")\n",
        "\n",
        "photometric_transform = A.Compose([\n",
        "    A.RandomBrightnessContrast(p=0.5),\n",
        "    A.HueSaturationValue(p=0.5),\n",
        "    A.GaussianBlur(blur_limit=(3, 3), p=0.3)\n",
        "], bbox_params=A.BboxParams(format='yolo', label_fields=['labels']))\n",
        "\n",
        "def process_image(image_path, label_path, out_images_dir, out_labels_dir, num_augments=5):\n",
        "\n",
        "    image = cv2.imread(image_path)\n",
        "    if image is None:\n",
        "        print(f\"Не удалось загрузить изображение: {image_path}\")\n",
        "        return\n",
        "    image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "    bboxes, labels = load_labels(label_path)\n",
        "\n",
        "    bboxes_class0 = []\n",
        "    labels_class0 = []\n",
        "    bboxes_other = []\n",
        "    labels_other = []\n",
        "    for bbox, label in zip(bboxes, labels):\n",
        "        if label == 0:\n",
        "            bboxes_class0.append(bbox)\n",
        "            labels_class0.append(label)\n",
        "        else:\n",
        "            bboxes_other.append(bbox)\n",
        "            labels_other.append(label)\n",
        "\n",
        "    base_filename = os.path.splitext(os.path.basename(image_path))[0]\n",
        "\n",
        "    for i in range(num_augments):\n",
        "        try:\n",
        "            augmented_result = photometric_transform(image=image_rgb, bboxes=bboxes_class0, labels=labels_class0)\n",
        "        except Exception as e:\n",
        "            print(f\"Ошибка при аугментации {base_filename}_aug_{i}: {e}\")\n",
        "            print(\"Пропускаем аугментацию для этой версии.\")\n",
        "            continue\n",
        "\n",
        "        aug_image = augmented_result['image']\n",
        "        aug_bboxes_class0 = augmented_result['bboxes']\n",
        "        aug_labels_class0 = augmented_result['labels']\n",
        "\n",
        "        combined_bboxes = aug_bboxes_class0 + bboxes_other\n",
        "        combined_labels = aug_labels_class0 + labels_other\n",
        "\n",
        "        aug_image_bgr = cv2.cvtColor(aug_image, cv2.COLOR_RGB2BGR)\n",
        "        out_image_path = os.path.join(out_images_dir, f\"{base_filename}_aug_{i}.jpg\")\n",
        "        out_label_path = os.path.join(out_labels_dir, f\"{base_filename}_aug_{i}.txt\")\n",
        "        cv2.imwrite(out_image_path, aug_image_bgr)\n",
        "        save_labels(out_label_path, combined_bboxes, combined_labels)\n",
        "        print(f\"Обработано и сохранено: {os.path.basename(out_image_path)}\")\n",
        "\n",
        "for filename in os.listdir(train_images_dir):\n",
        "    if not filename.lower().endswith(('.jpg', '.jpeg', '.png')):\n",
        "        continue\n",
        "    image_path = os.path.join(train_images_dir, filename)\n",
        "    label_filename = os.path.splitext(filename)[0] + \".txt\"\n",
        "    label_path = os.path.join(train_labels_dir, label_filename)\n",
        "    process_image(image_path, label_path, augmented_images_dir, augmented_labels_dir, num_augments=5)"
      ],
      "metadata": {
        "id": "HJaSMYRUAyEH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_dict = {\n",
        "    \"train\": \"/gdrive/MyDrive/работа/fire_and_smoke_detection/data/475_fire_train/train_augmented/images\",\n",
        "    \"val\": \"/gdrive/MyDrive/работа/fire_and_smoke_detection/data/475_fire_train/dev/images\",\n",
        "    \"test\": \"/gdrive/MyDrive/работа/fire_and_smoke_detection/data/474_fire_val/images\",\n",
        "    \"nc\": 2,\n",
        "    \"names\": [\"smoke\", \"fire\"]\n",
        "}\n",
        "\n",
        "\n",
        "yaml_path_augmented = \"data_augmented.yaml\"\n",
        "with open(yaml_path_augmented, \"w\") as f:\n",
        "    yaml.dump(data_dict, f)\n",
        "\n",
        "print(\"YAML конфигурация сохранена в\", yaml_path_augmented)"
      ],
      "metadata": {
        "id": "h-jOr92KATPn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = YOLO(\"yolov8m.pt\")\n",
        "\n",
        "train_results = model.train(\n",
        "    data=\"data_augmented.yaml\",\n",
        "    epochs=100,\n",
        "    imgsz=640,\n",
        "    batch=32,\n",
        "    optimizer=\"sgd\",\n",
        "    lr0=0.01\n",
        ")"
      ],
      "metadata": {
        "id": "Ro8ZPkLQAw4C"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}